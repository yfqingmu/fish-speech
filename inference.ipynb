{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yfqingmu/fish-speech/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtWD9aPAZbDA"
      },
      "source": [
        "# Fish Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-H3VZMZbDC"
      },
      "source": [
        "### For Windows User / win用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "BWxQ-YzKZbDD"
      },
      "outputs": [],
      "source": [
        "!chcp 65001"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 检查 GPU 是否可用\n",
        "if torch.cuda.is_available():\n",
        "    print(\"✅ GPU 可用！\")\n",
        "    print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "    print(f\"CUDA 版本: {torch.version.cuda}\")\n",
        "    print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
        "    print(f\"当前 GPU 名称: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU 内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"❌ 未检测到 GPU！\")\n",
        "    print(\"请检查是否已选择 GPU 运行时：\")\n",
        "    print(\"1. 顶部菜单：运行时 → 更改运行时类型\")\n",
        "    print(\"2. 硬件加速器：选择 'GPU'\")\n",
        "    print(\"3. 点击 '保存'\")\n",
        "    print(\"4. 重新运行此单元格\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqJn7dVpmbav",
        "outputId": "0bae95e8-89e0-40ce-ae73-8480c144f8a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU 可用！\n",
            "PyTorch 版本: 2.4.1+cu121\n",
            "CUDA 版本: 12.1\n",
            "GPU 数量: 1\n",
            "当前 GPU 名称: Tesla T4\n",
            "GPU 内存: 14.74 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-TTLdEsZbDE"
      },
      "source": [
        "### For Linux User / Linux 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XgOW1FvuZbDE",
        "outputId": "15668733-3937-49df-91fa-dc334d386177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCaJq6GeZbDF"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoTTliwTZbDF",
        "outputId": "33ad7d24-ef46-4759-bcfd-217f1f8f8891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]Downloading 'README.md' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.0d8d6dec1dd7f9e8739ddadb33b8c1b2cc5acc65.incomplete'\n",
            "Downloading 'model.pth' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/YT0Y2lJH9mHYafdr2d9j82hXvzY=.918dc960372cc1b77bbafb14c48ef7a1634ecf75d4eb85b78607223b780d6001.incomplete'\n",
            "Downloading 'firefly-gan-vq-fsq-8x1024-21hz-generator.pth' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Khmizewsuzbxb3XfvhhbrTGaoLE=.01b81dbf753224a156c3fe139b88bf0b9a0f54b11bee864f95e66511c3ccd754.incomplete'\n",
            "Downloading 'special_tokens.json' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Pdr1pnDFqf3r8xSTD-lPnaCpeRA=.db54e3cccbbaa1106ba8d56e810dffd42e325ab0.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.3f8edf91f7a0b152e5f8c30fd412c5d7e22020b5.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'tokenizer.tiktoken' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/zENsYUfT6EG2Nj68LEJ8oOfAxB8=.21dcfcb37df8da533b2d4fe0b867472f04cda62e.incomplete'\n",
            "\n",
            "\rREADME.md:   0% 0.00/1.68k [00:00<?, ?B/s]\u001b[A\rREADME.md: 100% 1.68k/1.68k [00:00<00:00, 14.9MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/README.md\n",
            "\n",
            "\rconfig.json:   0% 0.00/697 [00:00<?, ?B/s]\u001b[A\rconfig.json: 100% 697/697 [00:00<00:00, 7.44MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/config.json\n",
            "\n",
            "\r.gitattributes:   0% 0.00/1.52k [00:00<?, ?B/s]\u001b[A\r.gitattributes: 100% 1.52k/1.52k [00:00<00:00, 12.7MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/.gitattributes\n",
            "\rFetching 7 files:  14% 1/7 [00:00<00:00,  6.33it/s]\n",
            "\rspecial_tokens.json:   0% 0.00/31.0k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\rtokenizer.tiktoken:   0% 0.00/1.70M [00:00<?, ?B/s]\u001b[A\u001b[A\rspecial_tokens.json: 100% 31.0k/31.0k [00:00<00:00, 2.94MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/special_tokens.json\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   0% 0.00/189M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "tokenizer.tiktoken: 100% 1.70M/1.70M [00:00<00:00, 17.1MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/tokenizer.tiktoken\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   6% 10.5M/189M [00:00<00:02, 69.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   1% 10.5M/1.28G [00:00<00:17, 74.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   2% 31.5M/1.28G [00:00<00:10, 113MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  17% 31.5M/189M [00:00<00:01, 106MB/s] \u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  22% 41.9M/189M [00:00<00:01, 97.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   4% 52.4M/1.28G [00:00<00:11, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  33% 62.9M/189M [00:00<00:01, 95.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   6% 73.4M/1.28G [00:00<00:12, 99.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  39% 73.4M/189M [00:00<00:01, 94.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   7% 94.4M/1.28G [00:00<00:11, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  50% 94.4M/189M [00:00<00:00, 106MB/s] \u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  61% 115M/189M [00:01<00:00, 125MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model.pth:   9% 115M/1.28G [00:01<00:09, 117MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  72% 136M/189M [00:01<00:00, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  11% 136M/1.28G [00:01<00:08, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  83% 157M/189M [00:01<00:00, 143MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  12% 157M/1.28G [00:01<00:08, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  95% 178M/189M [00:01<00:00, 147MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth: 100% 189M/189M [00:01<00:00, 123MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\n",
            "Fetching 7 files:  57% 4/7 [00:01<00:01,  2.21it/s]\n",
            "\n",
            "\n",
            "model.pth:  16% 199M/1.28G [00:01<00:07, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  17% 220M/1.28G [00:01<00:07, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  20% 252M/1.28G [00:01<00:06, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  21% 273M/1.28G [00:02<00:05, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  23% 294M/1.28G [00:02<00:05, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  25% 315M/1.28G [00:02<00:06, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  26% 336M/1.28G [00:02<00:05, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  29% 367M/1.28G [00:02<00:05, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  30% 388M/1.28G [00:02<00:05, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  32% 409M/1.28G [00:02<00:05, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  34% 430M/1.28G [00:02<00:05, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  35% 451M/1.28G [00:03<00:04, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  37% 472M/1.28G [00:03<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  39% 493M/1.28G [00:03<00:04, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  40% 514M/1.28G [00:03<00:05, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  42% 535M/1.28G [00:03<00:05, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  44% 556M/1.28G [00:03<00:04, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  45% 577M/1.28G [00:03<00:04, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  47% 598M/1.28G [00:03<00:03, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  48% 619M/1.28G [00:04<00:03, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  50% 640M/1.28G [00:04<00:04, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  52% 661M/1.28G [00:04<00:03, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  53% 682M/1.28G [00:04<00:03, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  55% 703M/1.28G [00:04<00:03, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  57% 724M/1.28G [00:04<00:03, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  58% 744M/1.28G [00:04<00:03, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  60% 765M/1.28G [00:05<00:03, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  62% 786M/1.28G [00:05<00:03, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  63% 807M/1.28G [00:05<00:02, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  65% 828M/1.28G [00:05<00:02, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  67% 849M/1.28G [00:05<00:02, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  68% 870M/1.28G [00:05<00:02, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  71% 902M/1.28G [00:05<00:02, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  72% 923M/1.28G [00:09<00:16, 21.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  74% 944M/1.28G [00:09<00:11, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  76% 965M/1.28G [00:09<00:08, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  77% 986M/1.28G [00:09<00:05, 49.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  79% 1.01G/1.28G [00:09<00:04, 59.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  81% 1.03G/1.28G [00:09<00:03, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  82% 1.05G/1.28G [00:10<00:03, 75.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  84% 1.07G/1.28G [00:10<00:02, 86.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  85% 1.09G/1.28G [00:10<00:01, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  87% 1.11G/1.28G [00:10<00:01, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  90% 1.14G/1.28G [00:10<00:00, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  91% 1.16G/1.28G [00:10<00:00, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  93% 1.18G/1.28G [00:10<00:00, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  95% 1.21G/1.28G [00:10<00:00, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  96% 1.23G/1.28G [00:11<00:00, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  98% 1.25G/1.28G [00:11<00:00, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth: 100% 1.28G/1.28G [00:11<00:00, 112MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/model.pth\n",
            "Fetching 7 files: 100% 7/7 [00:11<00:00,  1.66s/it]\n",
            "/content/fish-speech/checkpoints/fish-speech-1.5\n"
          ]
        }
      ],
      "source": [
        "# For Chinese users, you probably want to use mirror to accelerate downloading\n",
        "# !set HF_ENDPOINT=https://hf-mirror.com\n",
        "# !export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdw1kmHRZ7lB",
        "outputId": "484d5ca4-4fb6-4193-f287-aefddafa9e66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fish-speech' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fish-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV2mI1MNaD4c",
        "outputId": "9116884b-3ee7-4a80-ef12-4efe0d4dccd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htzkdmxJdaHn",
        "outputId": "867c0255-9275-4e8c-fbed-8eb469ebd2b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: torchvision==0.19.1 in /usr/local/lib/python3.11/dist-packages (0.19.1)\n",
            "Requirement already satisfied: torchaudio==2.4.1 in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libsox-dev ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yLAs9_whFlz",
        "outputId": "5f943bd0-a6ef-4e61-a07e-c194c38c75b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libsox-dev is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install build-essential \\\n",
        "    cmake \\\n",
        "    libasound-dev \\\n",
        "    portaudio19-dev \\\n",
        "    libportaudio2 \\\n",
        "    libportaudiocpp0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkvH9VfhOWd",
        "outputId": "6d3ea813-358e-4ff6-8b72-7900fb1b7bd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libasound2-dev' instead of 'libasound-dev'\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libasound2-dev is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libportaudio2 is already the newest version (19.6.0-1.1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1.1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -e .[stable]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rRfSlDshSAI",
        "outputId": "613dc4bc-0523-427b-ae55-6b97f21d56bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (4.52.2)\n",
            "Requirement already satisfied: datasets==2.18.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: lightning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.5.1.post0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: gradio>5.0.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.32.0)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.19.11)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.71.0)\n",
            "Requirement already satisfied: kui>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.9.2)\n",
            "Requirement already satisfied: uvicorn>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.34.3)\n",
            "Requirement already satisfied: loguru>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.7.3)\n",
            "Requirement already satisfied: loralib>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: pyrootutils>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.0.4)\n",
            "Requirement already satisfied: vector_quantize_pytorch==1.14.24 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.14.24)\n",
            "Requirement already satisfied: resampy>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.4.3)\n",
            "Requirement already satisfied: einx==0.2.2 in /usr/local/lib/python3.11/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.23.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.25.1)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.2.14)\n",
            "Requirement already satisfied: faster_whisper in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: modelscope==1.17.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: funasr==1.1.5 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.1.5)\n",
            "Requirement already satisfied: opencc-python-reimplemented==0.1.7 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: silero-vad in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.1.2)\n",
            "Requirement already satisfied: ormsgpack in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.10.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: pydantic==2.9.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.9.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.31.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.6)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (1.15.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.18.1)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.42.1)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.19.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.5.7)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.6.2.2)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.2 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.10.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.10.18)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.2.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.15.3)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio>5.0.0->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Requirement already satisfied: baize>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from kui>=1.6.0->fish-speech==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (0.14.3)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (2.5.1.post0)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from pyrootutils>=1.0.4->fish-speech==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.19.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.5.82)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.3.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (1.3.6)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (4.6.0)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (14.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.43.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (25.2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>5.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (3.23.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (2.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->funasr==1.1.5->fish-speech==0.1.0) (0.5.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (43.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (10.0)\n",
            "Building wheels for collected packages: fish-speech\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=10384 sha256=e17ed7c412a79842288047aae2889ea4929a0db79826325fa7a8eb00b71d30e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4hx_xv3o/wheels/1d/8d/79/64aa115a26c1628f19c01f0b6214e49c83c75365353fa810b5\n",
            "Successfully built fish-speech\n",
            "Installing collected packages: fish-speech\n",
            "  Attempting uninstall: fish-speech\n",
            "    Found existing installation: fish-speech 0.1.0\n",
            "    Uninstalling fish-speech-0.1.0:\n",
            "      Successfully uninstalled fish-speech-0.1.0\n",
            "Successfully installed fish-speech-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at8y6uQ9hnUD",
        "outputId": "230c029a-797c-4734-bd5b-56ed61138122"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]\rFetching 7 files: 100% 7/7 [00:00<00:00, 3322.41it/s]\n",
            "/content/fish-speech/checkpoints/fish-speech-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i \"paimon.wav\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyHDNY2wdxEn",
        "outputId": "f57ecdc3-1875-4e0e-b22d-90d59fdcd9ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "\u001b[32m2025-06-02 03:18:30.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2025-06-02 03:18:30.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mProcessing in-place reconstruction of paimon.wav\u001b[0m\n",
            "\u001b[32m2025-06-02 03:18:30.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mLoaded audio with 19.81 seconds\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/residual_fsq.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled = False):\n",
            "\u001b[32m2025-06-02 03:18:31.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mGenerated indices of shape torch.Size([8, 427])\u001b[0m\n",
            "\u001b[32m2025-06-02 03:18:33.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mGenerated audio of shape torch.Size([1, 1, 874496]), equivalent to 19.83 seconds from 427 features, features/second: 21.53\u001b[0m\n",
            "\u001b[32m2025-06-02 03:18:33.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mSaved audio to fake.wav\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"峻峭的山谷环抱其中，山水相依，大气磅礴，如诗如画，令人陶醉。\" \\\n",
        "    --prompt-text \"山川壮丽，江河奔腾，绿水青山形成一幅美丽的画卷，这气势磅礴的场面让人心旷神怡，感受到大自然的神奇与壮美。\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5\" \\\n",
        "    --num-samples 2 \\\n",
        "    --compile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiZt9m5Zj6B8",
        "outputId": "e7cb03cd-7159-42a1-a9a4-12750e52a32f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-06-02 03:21:46.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1056\u001b[0m - \u001b[1mLoading model ...\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:01.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:01.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:01.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m695\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:03.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1070\u001b[0m - \u001b[1mTime to load model: 16.80 seconds\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:03.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 峻峭的山谷环抱其中，山水相依，大气磅礴，如诗如画，令人陶醉。\u001b[0m\n",
            "\u001b[32m2025-06-02 03:22:03.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 1/2\u001b[0m\n",
            "  0% 0/7675 [00:00<?, ?it/s]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "  0% 1/7675 [02:50<364:28:01, 170.98s/it]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  0% 2/7675 [03:04<166:44:10, 78.23s/it] /usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  3% 235/7675 [03:26<1:49:13,  1.14it/s]\n",
            "\u001b[32m2025-06-02 03:25:31.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m851\u001b[0m - \u001b[1mCompilation time: 208.27 seconds\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 237 tokens in 208.27 seconds, 1.14 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 0.73 GB/s\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 1.86 GB\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1103\u001b[0m - \u001b[1mSampled text: 峻峭的山谷环抱其中，山水相依，大气磅礴，如诗如画，令人陶醉。\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1108\u001b[0m - \u001b[1mSaved codes to temp/codes_0.npy\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1109\u001b[0m - \u001b[1mNext sample\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:31.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 2/2\u001b[0m\n",
            "  3% 240/7675 [00:23<11:59, 10.34it/s]\n",
            "\u001b[32m2025-06-02 03:25:55.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 242 tokens in 23.70 seconds, 10.21 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 6.51 GB/s\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.12 GB\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1103\u001b[0m - \u001b[1mSampled text: 峻峭的山谷环抱其中，山水相依，大气磅礴，如诗如画，令人陶醉。\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1108\u001b[0m - \u001b[1mSaved codes to temp/codes_1.npy\u001b[0m\n",
            "\u001b[32m2025-06-02 03:25:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1109\u001b[0m - \u001b[1mNext sample\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i \"temp/codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUzYsM4NreaQ",
        "outputId": "429eec51-d4f8-467e-fe8e-b9d3c8db2297"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "\u001b[32m2025-06-02 03:30:07.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2025-06-02 03:30:07.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mProcessing precomputed indices from temp/codes_0.npy\u001b[0m\n",
            "\u001b[32m2025-06-02 03:30:08.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mGenerated audio of shape torch.Size([1, 1, 483328]), equivalent to 10.96 seconds from 236 features, features/second: 21.53\u001b[0m\n",
            "\u001b[32m2025-06-02 03:30:08.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mSaved audio to fake.wav\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tYaTlBEZbDF"
      },
      "source": [
        "## WebUI Inference\n",
        "\n",
        "> You can use --compile to fuse CUDA kernels for faster inference (10x)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GllQS3WLZbDG",
        "outputId": "b4c807d3-d04d-4314-86c4-87257ade6907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-06-02 03:35:54.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:06.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:06.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:06.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m695\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:07.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "\u001b[32m2025-06-02 03:36:09.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.vqgan.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:09.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:09.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "\u001b[32m2025-06-02 03:36:09.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 1/1\u001b[0m\n",
            "  0% 0/1023 [00:00<?, ?it/s]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1607: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "  0% 1/1023 [02:53<49:06:59, 173.01s/it]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  0% 2/1023 [03:08<22:51:15, 80.58s/it] /usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  2% 23/1023 [03:10<2:18:16,  8.30s/it]\n",
            "\u001b[32m2025-06-02 03:39:21.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m851\u001b[0m - \u001b[1mCompilation time: 191.97 seconds\u001b[0m\n",
            "\u001b[32m2025-06-02 03:39:21.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 25 tokens in 191.97 seconds, 0.13 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-06-02 03:39:21.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 0.08 GB/s\u001b[0m\n",
            "\u001b[32m2025-06-02 03:39:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 1.76 GB\u001b[0m\n",
            "\u001b[32m2025-06-02 03:39:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 24])\u001b[0m\n",
            "\u001b[32m2025-06-02 03:39:22.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        }
      ],
      "source": [
        "!python tools/run_webui.py \\\n",
        "    --llama-checkpoint-path checkpoints/fish-speech-1.5 \\\n",
        "    --decoder-checkpoint-path checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth \\\n",
        "    --compile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\\n",
        "  | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null \\\n",
        "  && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" \\\n",
        "  | sudo tee /etc/apt/sources.list.d/ngrok.list \\\n",
        "  && sudo apt update \\\n",
        "  && sudo apt install ngrok"
      ],
      "metadata": {
        "id": "-4nu0C_Ivkta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ngrok"
      ],
      "metadata": {
        "id": "9IzDVxmOv6cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaEZLklvZbDG"
      },
      "source": [
        "## Break-down CLI Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMqX4nTWZbDH"
      },
      "source": [
        "### 1. Encode reference audio: / 从语音生成 prompt:\n",
        "\n",
        "You should get a `fake.npy` file.\n",
        "\n",
        "你应该能得到一个 `fake.npy` 文件."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "xJHCTuhXZbDH"
      },
      "outputs": [],
      "source": [
        "## Enter the path to the audio file here\n",
        "src_audio = r\"D:\\PythonProject\\vo_hutao_draw_appear.wav\"\n",
        "\n",
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i {src_audio} \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO--92nCZbDI"
      },
      "source": [
        "### 2. Generate semantic tokens from text: / 从文本生成语义 token:\n",
        "\n",
        "> This command will create a codes_N file in the working directory, where N is an integer starting from 0.\n",
        "\n",
        "> You may want to use `--compile` to fuse CUDA kernels for faster inference (~30 tokens/second -> ~300 tokens/second).\n",
        "\n",
        "> 该命令会在工作目录下创建 codes_N 文件, 其中 N 是从 0 开始的整数.\n",
        "\n",
        "> 您可以使用 `--compile` 来融合 cuda 内核以实现更快的推理 (~30 tokens/秒 -> ~300 tokens/秒)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "wKaSaNAdZbDI"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"hello world\" \\\n",
        "    --prompt-text \"The text corresponding to reference audio\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5\" \\\n",
        "    --num-samples 2\n",
        "    # --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymNhZxtWZbDI"
      },
      "source": [
        "### 3. Generate speech from semantic tokens: / 从语义 token 生成人声:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "vdrl5deCZbDI"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i \"codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}